import traceback

import aiohttp
import asyncio
import os
import hashlib
from tqdm import tqdm
import aiofiles
import time
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional, AsyncGenerator, Any, Callable


@dataclass
class DownloadResult:
    """ä¸‹è½½ç»“æœ"""
    success: bool
    message: str
    error_type: str = ""
    total_size: int = 0
    downloaded_size: int = 0


@dataclass
class DownloadProgress:
    """ä¸‹è½½è¿›åº¦ä¿¡æ¯"""
    stage: str  # é˜¶æ®µï¼štesting, downloading, completed
    source_speeds: Dict[int, float]  # å„æºé€Ÿåº¦
    fastest_source: Optional[int] = None  # æœ€å¿«æºç´¢å¼•
    downloaded: int = 0  # å·²ä¸‹è½½å­—èŠ‚æ•°
    total: int = 0  # æ€»å­—èŠ‚æ•°
    progress: float = 0.0  # è¿›åº¦ç™¾åˆ†æ¯”
    speed: float = 0.0  # å½“å‰é€Ÿåº¦ KB/s
    remaining_time: float = 0.0  # å‰©ä½™æ—¶é—´ï¼ˆç§’ï¼‰


@dataclass
class DownloadSource:
    """ä¸‹è½½æºä¿¡æ¯"""
    url: str
    speed: float = 0.0  # KB/s
    downloaded: int = 0  # å·²ä¸‹è½½å­—èŠ‚æ•°
    active: bool = True
    task: Optional[asyncio.Task] = None
    session: Optional[aiohttp.ClientSession] = None
    response: Optional[aiohttp.ClientResponse] = None
    file_handle: Optional[Any] = None


# è¿›åº¦å›è°ƒç±»å‹
ProgressCallback = Callable[[DownloadProgress], None]


async def download_source_with_progress(source: DownloadSource, temp_path: str, chunk_size: int):
    """å¸¦é€Ÿåº¦ç›‘æ§çš„å•ä¸ªæºä¸‹è½½"""
    try:
        timeout = aiohttp.ClientTimeout(connect=10, sock_read=30, total=60)

        async with aiohttp.ClientSession(timeout=timeout) as session:
            source.session = session
            async with session.get(source.url) as response:
                source.response = response
                if response.status != 200:
                    source.speed = 0
                    return

                source.file_handle = await aiofiles.open(temp_path, 'wb')
                start_time = time.time()
                downloaded = 0

                try:
                    async for chunk in response.content.iter_chunked(chunk_size):
                        if not source.active:
                            break

                        if chunk:
                            await source.file_handle.write(chunk)
                            downloaded += len(chunk)
                            source.downloaded = downloaded

                            # è®¡ç®—å®æ—¶é€Ÿåº¦
                            elapsed = time.time() - start_time
                            if elapsed > 0:
                                source.speed = downloaded / elapsed / 1024
                finally:
                    if source.file_handle:
                        await source.file_handle.close()
                        source.file_handle = None

    except asyncio.CancelledError:
        pass
    except Exception as e:
        source.speed = 0
        # print(f"ä¸‹è½½æº {source.url} å¤±è´¥: {e}")
    finally:
        # å®‰å…¨åœ°æ¸…ç†èµ„æº
        if source.file_handle:
            try:
                await source.file_handle.close()
            except Exception:
                pass
            source.file_handle = None

        if source.response:
            try:
                source.response.close()
            except Exception:
                pass
            source.response = None

        if source.session:
            try:
                await source.session.close()
            except Exception:
                pass
            source.session = None


async def safe_delete_file(file_path: str, max_retries: int = 5, retry_delay: float = 0.5):
    """å®‰å…¨åˆ é™¤æ–‡ä»¶"""
    for attempt in range(max_retries):
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
            return True
        except PermissionError:
            if attempt < max_retries - 1:
                await asyncio.sleep(retry_delay)
            else:
                return False
        except FileNotFoundError:
            return True
        except Exception:
            return False
    return False


async def stop_source_download(source: DownloadSource, temp_file: str):
    """å®‰å…¨åœæ­¢æºä¸‹è½½"""
    try:
        source.active = False

        # å®‰å…¨åœ°å…³é—­èµ„æº
        if source.file_handle:
            try:
                await source.file_handle.close()
            except Exception:
                pass
            source.file_handle = None

        if source.response:
            try:
                source.response.close()
            except Exception:
                pass
            source.response = None

        if source.session:
            try:
                await source.session.close()
            except Exception:
                pass
            source.session = None

        # å–æ¶ˆä»»åŠ¡
        if source.task and not source.task.done():
            source.task.cancel()
            try:
                await asyncio.wait_for(source.task, timeout=3.0)
            except (asyncio.CancelledError, asyncio.TimeoutError):
                pass

        await asyncio.sleep(0.5)

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        if temp_file:
            await safe_delete_file(temp_file)

    except Exception as e:
        print(f"åœæ­¢ä¸‹è½½æºæ—¶å‡ºé”™: {e}")


async def download_from_fastest_source(source, save_path: str,
                                       initial_data: bytes, md5_hash,
                                       chunk_size: int = 8192,
                                       max_retries: int = 5):
    """ä»æœ€å¿«çš„æºç»§ç»­ä¸‹è½½ï¼Œå¤±è´¥æ—¶é‡è¯•æœ€å¤š max_retries æ¬¡"""
    total_downloaded = len(initial_data)
    start_time = time.time()
    last_update_time = start_time
    last_downloaded = total_downloaded

    for attempt in range(1, max_retries + 1):
        try:
            timeout = aiohttp.ClientTimeout(connect=10, sock_read=30, total=300)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                headers = {}
                if total_downloaded > 0:
                    headers['Range'] = f'bytes={total_downloaded}-'

                async with session.get(source.url, headers=headers) as response:
                    if response.status not in [200, 206]:
                        raise Exception(f"HTTP çŠ¶æ€ç  {response.status}")

                    total_size = int(response.headers.get('content-length', 0)) + total_downloaded
                    current_speed = 0
                    async with aiofiles.open(save_path, 'ab') as file:
                        async for chunk in response.content.iter_chunked(chunk_size):
                            if chunk:
                                await file.write(chunk)
                                md5_hash.update(chunk)
                                total_downloaded += len(chunk)
                                current_time = time.time()
                                # elapsed = current_time - start_time
                                # current_speed = total_downloaded / elapsed / 1024 if elapsed > 0 else 0
                                # è®¡ç®—ç¬æ—¶é€Ÿåº¦ï¼ˆåŸºäºæœ€è¿‘çš„æ•°æ®ï¼‰
                                time_diff = current_time - last_update_time
                                if time_diff >= 2.0:  # æ¯ç§’æ›´æ–°ä¸€æ¬¡é€Ÿåº¦è®¡ç®—
                                    downloaded_diff = total_downloaded - last_downloaded
                                    current_speed = downloaded_diff / time_diff / 1024 if time_diff > 0 else 0
                                    last_update_time = current_time
                                    last_downloaded = total_downloaded
                                yield total_downloaded, total_size, current_speed, True

                    yield total_downloaded, total_size, 0.0, True
                    return  # ä¸‹è½½æˆåŠŸï¼Œé€€å‡ºå¾ªç¯

        except Exception as e:
            if attempt < max_retries:
                print(f"ä¸‹è½½ä¸´æ—¶ä¸­æ–­ï¼Œç»§ç»­å°è¯•ä¸‹è½½: {e}")
                await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            else:
                yield total_downloaded, 0, 0.0, False
                return


def format_file_size(size_bytes: float) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes == 0:
        return "0 B"

    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    return f"{size_bytes:.2f} {size_names[i]}"


def format_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´"""
    if seconds <= 0:
        return "0ç§’"

    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)

    if hours > 0:
        return f"{hours}å°æ—¶{minutes}åˆ†{secs}ç§’"
    elif minutes > 0:
        return f"{minutes}åˆ†{secs}ç§’"
    else:
        return f"{secs}ç§’"


async def multi_source_download(sources: List[str], save_path: str,
                                expected_md5: Optional[str] = None,
                                test_duration: int = 10,
                                chunk_size: int = 8192,
                                progress_callback: Optional[ProgressCallback] = None) -> Tuple[bool, str]:
    """
    å¤šæºä¸‹è½½ï¼šæµ‹è¯•åé€‰æ‹©æœ€å¿«çš„æºç»§ç»­ä¸‹è½½
    """

    def update_progress(stage: str, source_speeds: Dict[int, float] = None,
                        fastest_source: Optional[int] = None, downloaded: int = 0,
                        total: int = 0, speed: float = 0.0, remaining_time: float = 0.0):
        if progress_callback:
            if source_speeds is None:
                source_speeds = {}
            # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
            progress_percent = downloaded / total if total > 0 else 0.0
            progress_info = DownloadProgress(
                stage=stage,
                source_speeds=source_speeds,
                fastest_source=fastest_source,
                downloaded=downloaded,
                total=total,
                progress=progress_percent,
                speed=speed,
                remaining_time=remaining_time
            )
            progress_callback(progress_info)

    download_sources = [DownloadSource(url=url) for url in sources]
    temp_dir = os.path.dirname(save_path)
    os.makedirs(temp_dir, exist_ok=True)

    source_files = []
    for i, source in enumerate(download_sources):
        temp_file = os.path.join(temp_dir, f"temp_source_{i}.part")
        source_files.append(temp_file)

    main_temp_path = save_path + ".downloading"
    md5_hash = hashlib.md5()

    try:
        # é˜¶æ®µ1: é€Ÿåº¦æµ‹è¯•
        update_progress("testing", source_speeds={i: 0.0 for i in range(len(sources))})

        tasks = []
        for i, source in enumerate(download_sources):
            task = asyncio.create_task(
                download_source_with_progress(source, source_files[i], chunk_size)
            )
            source.task = task
            tasks.append(task)

        start_test_time = time.time()
        while time.time() - start_test_time < test_duration:
            # æ›´æ–°æµ‹è¯•é˜¶æ®µè¿›åº¦
            source_speeds = {i: source.speed for i, source in enumerate(download_sources)}
            elapsed = time.time() - start_test_time
            test_progress_percent = min(elapsed / test_duration, 1.0)
            update_progress(
                stage="testing",
                source_speeds=source_speeds,
                downloaded=int(elapsed * 1000),
                total=test_duration * 1000,
                speed=0.0,
                remaining_time=0.0
            )
            await asyncio.sleep(0.5)

        # é€‰æ‹©æœ€å¿«çš„æº
        active_sources = [s for s in download_sources if s.speed > 0]
        if not active_sources:
            return False, "æ‰€æœ‰ä¸‹è½½æºæµ‹è¯•å¤±è´¥"

        fastest_source = max(active_sources, key=lambda x: x.speed)
        fastest_index = download_sources.index(fastest_source)

        print(f"ğŸ¯ æµ‹è¯•å®Œæˆï¼Œé€‰æ‹©æœ€å¿«ä¸‹è½½æº: æº{fastest_index} (é€Ÿåº¦: {fastest_source.speed:.1f}KB/s)")

        # åœæ­¢å…¶ä»–ä¸‹è½½ä»»åŠ¡
        stop_tasks = []
        for i, source in enumerate(download_sources):
            if source != fastest_source:
                stop_tasks.append(stop_source_download(source, source_files[i]))

        if stop_tasks:
            await asyncio.gather(*stop_tasks, return_exceptions=True)

        # é˜¶æ®µ2: ä»æœ€å¿«æºç»§ç»­ä¸‹è½½

        # è·å–æœ€å¿«æºå·²ä¸‹è½½çš„æ•°æ®
        total_downloaded = 0
        initial_data = b""
        if os.path.exists(source_files[fastest_index]):
            try:
                await stop_source_download(fastest_source, "")
                await asyncio.sleep(1)

                with open(source_files[fastest_index], 'rb') as f:
                    initial_data = f.read()
                    total_downloaded = len(initial_data)

                # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤å®ƒ
                if os.path.exists(main_temp_path):
                    await safe_delete_file(main_temp_path)

                async with aiofiles.open(main_temp_path, 'wb') as f:
                    await f.write(initial_data)
                    md5_hash.update(initial_data)

                print(f"âœ… å·²å¤ç”¨ {total_downloaded / 1024 / 1024:.2f} MB æ•°æ®\n")

            except Exception as e:
                print(f"âŒ è¯»å–å·²ä¸‹è½½æ•°æ®å¤±è´¥: {e}")
                initial_data = b""
                total_downloaded = 0

        await safe_delete_file(source_files[fastest_index])

        # ä¸»ä¸‹è½½é˜¶æ®µ
        download_success = False
        download_start_time = time.time()

        try:
            download_gen = download_from_fastest_source(
                fastest_source, main_temp_path, initial_data, md5_hash, chunk_size
            )

            async for current_downloaded, total_size, current_speed, still_going in download_gen:
                if still_going:
                    # è®¡ç®—å‰©ä½™æ—¶é—´
                    remaining_time = 0.0
                    if current_speed > 0 and total_size > current_downloaded:
                        remaining_bytes = total_size - current_downloaded
                        remaining_time = remaining_bytes / (current_speed * 1024)  # è½¬æ¢ä¸ºç§’

                    update_progress(
                        stage="downloading",
                        source_speeds={fastest_index: current_speed},
                        fastest_source=fastest_index,
                        downloaded=current_downloaded,
                        total=total_size,
                        speed=current_speed,
                        remaining_time=remaining_time
                    )
                else:
                    break
            else:
                download_success = True

        except Exception as e:
            print(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            traceback.print_exc()
            download_success = False

        if not download_success:
            return False, "ä»æœ€å¿«æºä¸‹è½½å¤±è´¥"

        # å®Œæˆé˜¶æ®µ
        if os.path.exists(main_temp_path):
            # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
            if os.path.exists(save_path):
                await safe_delete_file(save_path)

            os.rename(main_temp_path, save_path)
            final_size = os.path.getsize(save_path)
            update_progress(
                stage="completed",
                source_speeds={fastest_index: 0.0},
                fastest_source=fastest_index,
                downloaded=final_size,
                total=final_size,
                speed=0.0,
                remaining_time=0.0
            )
        else:
            return False, "ä¸‹è½½æ–‡ä»¶ä¸å­˜åœ¨"

        if expected_md5:
            actual_md5 = md5_hash.hexdigest()
            if actual_md5 != expected_md5:
                return False, f"MD5æ ¡éªŒå¤±è´¥: æœŸæœ› {expected_md5}, å®é™… {actual_md5}"
            print("âœ… MD5æ ¡éªŒé€šè¿‡")

        return True, "ä¸‹è½½æˆåŠŸ"

    except Exception as e:
        return False, f"ä¸‹è½½å¤±è´¥: {str(e)}"
    finally:
        cleanup_tasks = []
        for i, (source, temp_file) in enumerate(zip(download_sources, source_files)):
            cleanup_tasks.append(stop_source_download(source, temp_file))
        if cleanup_tasks:
            await asyncio.gather(*cleanup_tasks, return_exceptions=True)
        await safe_delete_file(main_temp_path)


# ä½¿ç”¨ç¤ºä¾‹
async def main():
    print("=== å¤šæºä¸‹è½½æµ‹è¯•ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰===")

    # è¿›åº¦å›è°ƒå‡½æ•°
    def progress_callback(progress: DownloadProgress):
        if progress.stage == "testing":
            print(f"\rğŸ”„ æµ‹è¯•é˜¶æ®µ - è¿›åº¦: {progress.progress * 100:.1f}% | " +
                  " | ".join([f"æº{i}: {speed:.1f}KB/s" for i, speed in progress.source_speeds.items()]), end="",
                  flush=True)
        elif progress.stage == "downloading":
            # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°å’Œå‰©ä½™æ—¶é—´
            total_size_str = format_file_size(progress.total)
            downloaded_str = format_file_size(progress.downloaded)
            remaining_time_str = format_time(progress.remaining_time)

            print(f"\rğŸ“¥ ä¸‹è½½é˜¶æ®µ - è¿›åº¦: {progress.progress * 100:.1f}% | " +
                  f"å¤§å°: {downloaded_str}/{total_size_str} | " +
                  f"é€Ÿåº¦: {progress.speed:.1f}KB/s | " +
                  f"å‰©ä½™: {remaining_time_str}", end="", flush=True)
        elif progress.stage == "completed":
            total_size_str = format_file_size(progress.downloaded)
            print(f"âœ… ä¸‹è½½å®Œæˆ! æ€»å¤§å°: {total_size_str}")

    # å¤šä¸ªä¸‹è½½åœ°å€
    sources = [
        "https://r2.aituple.cn/indexdoc_win.zst",
        "https://pub-023efc67a2674a00bbe4437f46ec740c.r2.dev/indexdoc_win.zst",
    ]

    save_path = "./downloads/Cyberduck.exe"

    success, message = await multi_source_download(
        sources=sources,
        save_path=save_path,
        test_duration=5,
        progress_callback=progress_callback
    )

    if success:
        print(f"âœ… {message}")
    else:
        print(f"âŒ {message}")


if __name__ == "__main__":
    os.makedirs("./downloads", exist_ok=True)
    asyncio.run(main())